{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB 2 Boosting Machine Learning Algorithm\n",
    "\n",
    "## Introduction\n",
    "Reference: Danish Harron: \"Python Machine Learning Case Studies\" Chapter 5. 2017.\n",
    "\n",
    "This workshop reviews making using the classification methods developed in the application of data minning so as to spot out the insight froma. complicated data set for further A/B Test applications.\n",
    "\n",
    "The case here about a pediatric surgeon and clinic supervisor at Ohio Clinic, was in big trouble, facing clinic losses for the third consecutive year. \n",
    "\n",
    "The supervisor had recently been promoted to this position, but she knew for a fact that the clinic had been doing due diligence in terms of efficiency. What surprised her most was that the hospital was incurring losses despite having the finest doctors available and no lack of scheduled appointments. \n",
    "\n",
    "She got the data log file and discovered reasons that losses are coming up even though the rate of appointments is going up. However, patients are not reporting at the time of their scheduled appointments, prompt not to meet following patients leading to many overtime work of staff, raising the costs. \n",
    "\n",
    "She believed that knowing which patients were likely not to show up would enable the hospital to take countermeasures to minimize the overtime work costs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python libraries:Â¶\n",
    "\n",
    "numpy, time for common language program function\n",
    "\n",
    "pandas for data file or database manilpulation\n",
    "\n",
    "IPython for data visulation\n",
    "\n",
    "statistics, sklearn, and scipy are for statistical and mathematical formula/function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "from matplotlib.pylab import rcParams\n",
    "import pandas_profiling as pdf\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import kernel_approximation\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.kernel_approximation import (RBFSampler,Nystroem)\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "rcParams['figure.figsize'] = 15, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('No-show-Issue-Comma-300k.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in list(data.columns):\n",
    "    print(\"{0:25} {1:}\".format(column, data[column].nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Wrangling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['Age'] < 0]['Age'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['Age'] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data['Handcap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['AwaitingTime'] = data['AwaitingTime'].apply(lambda x: abs(x))\n",
    "dow_mapping = {'Monday' : 0, 'Tuesday' : 1, 'Wednesday' : 2, 'Thursday' : 3, 'Friday' : 4, 'Saturday' : 5, 'Sunday' : 6}\n",
    "data['DayOfTheWeek'] = data['DayOfTheWeek'].map(dow_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Alcoholism'] = data['Alcoolism']\n",
    "del data['Alcoolism']\n",
    "data['HyperTension'] = data['HiperTension']\n",
    "del data['HiperTension']\n",
    "data['AppointmentDate'] = data['ApointmentData']\n",
    "del data['ApointmentData']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for field in ['Gender', 'Status']:\n",
    "    data[field] = pd.Categorical(data[field]).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_plots(discrete_vars):\n",
    "\n",
    "    plt.figure(figsize=(15,24.5))\n",
    "\n",
    "    for i, cv in enumerate(['Age']):\n",
    "        plt.subplot(7, 2, i+1)\n",
    "        plt.hist(data[cv], bins=len(data[cv].unique()))\n",
    "        plt.title(cv)\n",
    "        plt.ylabel('Frequency')\n",
    "\n",
    "    for i, dv in enumerate(discrete_vars):\n",
    "        plt.subplot(7, 2, i+3)\n",
    "        data[dv].value_counts().plot(kind='bar', title=dv)\n",
    "        plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_vars = ['Gender', 'DayOfTheWeek','Diabetes', 'Alcoholism', 'HyperTension', 'Smokes', 'AwaitingTime',\n",
    "                      'Tuberculosis', 'Scholarship', 'Sms_Reminder', 'Status']\n",
    "\n",
    "features_plots(discrete_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data['Age'], data['Status'], s=1)\n",
    "plt.title('Scatter plot of Age and Awaiting Time')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('No-show')\n",
    "plt.xlim(0, 120)\n",
    "plt.ylim(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.width', 100)\n",
    "pd.set_option('precision', 3)\n",
    "correlations = data[['Age', 'AwaitingTime']].corr(method='pearson')\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dow_status = data.groupby(['Sms_Reminder', 'Status'])['Sms_Reminder'].count().fillna(0)\n",
    "data_dow_status[[0, 1]].plot(kind='bar', stacked=True)\n",
    "plt.title('Frequency of people showing up and not showing up by number of SMS reminders sent')\n",
    "plt.xlabel('Number of SMS reminders')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dow_status = data.groupby(['DayOfTheWeek', 'Status'])['DayOfTheWeek'].count().unstack('Status').fillna(0)\n",
    "data_dow_status[[0, 1]].plot(kind='bar', stacked=True)\n",
    "plt.title('Frequency of people showing up and not showing up by Day of the week')\n",
    "plt.xlabel('Day of the week')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.boxplot(column=['Age'], return_type='axes', by='Status')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,3.5))\n",
    "\n",
    "for i, status in enumerate(['show ups', 'show ups']):\n",
    "\n",
    "    data_show = data[data['Status']==i]\n",
    "    plt.subplot(1, 2, i+1)\n",
    "\n",
    "    for gender in [0, 1]:\n",
    "        data_gender = data_show[data_show['Gender']==gender]\n",
    "        freq_age = data_gender['Age'].value_counts().sort_index()\n",
    "        freq_age.plot()\n",
    "\n",
    "    plt.title('Age wise frequency of patient %s for both genders'%status)\n",
    "    plt.xlabel('Age')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend(['Female', 'Male'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.boxplot(column=['AwaitingTime'], return_type='axes', by='Status')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: Extract more features from the date features (hour, min, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['AppointmentRegistration', 'AppointmentDate']: #'AppointmentRegistration', 'ApointmentData'\n",
    "    for index, component in enumerate(['year', 'month', 'day']):\n",
    "        data['%s_%s'%(col, component)] = data[col].apply(lambda x: int(x.split('T')[0].split('-')[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, component in enumerate(['hour']):\n",
    "    data['%s_%s'%('AppointmentRegistration', component)] = data['AppointmentRegistration'].apply(lambda x: int(x.split('T')[1][:-1].split(':')[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include a Boolean transformation of the features in your dataset like that done in Chapter 4. \n",
    "# This will increase the feature set which can become beneficial while training the model.\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.ProfileReport(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape, data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance(model_name, X_train, y_train, y_test, Y_pred):\n",
    "\n",
    "    print('Model name: %s'%model_name)\n",
    "    print('Test accuracy (Accuracy Score): %f'%metrics.accuracy_score(y_test, Y_pred))\n",
    "    print('Test accuracy (ROC AUC Score): %f'%metrics.roc_auc_score(y_test, Y_pred))\n",
    "    print('Train accuracy: %f'%clf.score(X_train, y_train))\n",
    "\n",
    "    fpr, tpr, thresholds = metrics.precision_recall_curve(y_test, Y_pred)\n",
    "    print('Area Under the Precision-Recall Curve: %f'%metrics.auc(fpr, tpr))\n",
    "    \n",
    "    false_positive_rate, true_positive_rate, thresholds = metrics.roc_curve(y_test, Y_pred)\n",
    "    roc_auc = metrics.auc(false_positive_rate, true_positive_rate)\n",
    "    \n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(false_positive_rate, true_positive_rate, 'b', label='AUC = %0.2f'% roc_auc)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0,1],[0,1],'r--')\n",
    "    plt.xlim([-0.1,1.2])\n",
    "    plt.ylim([-0.1,1.2])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_of_choice = ['Age', 'Gender', 'Diabetes', 'Alcoholism', 'HyperTension',\n",
    "                        'Scholarship', 'Sms_Reminder', \n",
    "                        'AppointmentDate_year', 'AppointmentDate_month', 'AppointmentDate_day',\n",
    "                     ]\n",
    "\n",
    "\n",
    "x = np.array(data[features_of_choice])\n",
    "y = np.array(data['Status'])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)\n",
    "model_performance('Decision tree classifier', x_train, y_train, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_feature = kernel_approximation.RBFSampler(gamma=1, random_state=1)\n",
    "X_train = rbf_feature.fit_transform(x_train)\n",
    "\n",
    "clf = SGDClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = rbf_feature.fit_transform(x_test)\n",
    "Y_pred = clf.predict(X_test)\n",
    "model_performance('Kernel approximation', X_train, y_train, y_test, Y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(random_state=10, learning_rate=0.1,\n",
    "    n_estimators=200, max_depth=5, max_features=10)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance('Gradient Boosting', x_train, y_train, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)\n",
    "model_performance('Random Forest', x_train, y_train, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, score in zip(features_of_choice, list(clf.feature_importances_)):\n",
    "        print('%s\\t%f'%(feature, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Excercise 1: Repeat gradient boosting classification but this time only consider the features it deemed important. Did AUC and ROC improve?\n",
    "features_of_choice2 = ['Age', 'Gender', 'Sms_Reminder', \n",
    "                        'AppointmentDate_month', 'AppointmentDate_day',]\n",
    "\n",
    "x2 = np.array(data[features_of_choice2])\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "\n",
    "clf2 = GradientBoostingClassifier(random_state=10, learning_rate=0.1,\n",
    "    n_estimators=200, max_depth=5, max_features=10)\n",
    "clf2.fit(x_train2, y_train2)\n",
    "y_pred2 = clf.predict(x_test2)\n",
    "model_performance('Gradient Boosting', x_train2, y_train2, y_test2, y_pred2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, score in zip(features_of_choice, list(clf2.feature_importances_)):\n",
    "        print('%s\\t%f'%(feature, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Excercise 2: Recently a new type of boosting, Xgboost, has been popular among data scientists. Apply that to our dataset, optimize using grid search, and see if it performs relatively better than gradient boosting.\n",
    "import xgboost as xgb\n",
    "\n",
    "params = {'max_depth':5, 'eta':0.1, 'silent':1, 'objective':'binary:hinge' }\n",
    "num_round = 10\n",
    "dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "dtest = xgb.DMatrix(x_test, label=y_test)\n",
    "bst = xgb.train(params, dtrain, num_round)\n",
    "y_pred4 = bst.predict(dtest)\n",
    "\n",
    "print(y_pred4)\n",
    "\n",
    "model_performance('XGBoost', x_train, y_train, y_test, y_pred4)\n",
    "xgb.plot_importance(bst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Excercise 3: Apply grid search to gradient boosting to fine-tune the parameters of learning rate, max_depth, etc.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf3 = GradientBoostingClassifier()\n",
    "params = {\"learning_rate\": [0.001, 0.1, 0.5], \"max_depth\":[3,5,7,10], \"n_estimators\":[100,200]}\n",
    "cv = GridSearchCV(estimator=clf3, param_grid=params)\n",
    "\n",
    "y_pred3 = cv.fit(x_train, y_train).predict(x_test)\n",
    "\n",
    "model_performance('Gradient Boosting', x_train, y_train, y_test, y_pred3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THE END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
